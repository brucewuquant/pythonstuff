{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pre_Final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "JRgkfqJWDTr4",
        "colab_type": "code",
        "outputId": "5a510e33-9bb3-4f04-e287-2a8e65d9d49c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install h2o\n",
        "!pip install pandarallel --user\n",
        "from pandarallel import pandarallel\n",
        "pandarallel.initialize(progress_bar = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h2o in /usr/local/lib/python3.6/dist-packages (3.24.0.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o) (0.8.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from h2o) (2.21.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o) (0.16.0)\n",
            "Requirement already satisfied: colorama>=0.3.8 in /usr/local/lib/python3.6/dist-packages (from h2o) (0.4.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (1.24.2)\n",
            "Collecting pandarallel\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/04/e90965979c4fb2cda792f5174e062df47ac6d49d7e28c72274d33430e551/pandarallel-1.1.0.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from pandarallel) (0.24.2)\n",
            "Collecting pyarrow>=0.12.1 (from pandarallel)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/25/094b122d828d24b58202712a74e661e36cd551ca62d331e388ff68bae91d/pyarrow-0.13.0-cp36-cp36m-manylinux1_x86_64.whl (48.5MB)\n",
            "    100% |████████████████████████████████| 48.5MB 247kB/s \n",
            "\u001b[?25hCollecting tqdm>=4.31.1 (from pandarallel)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n",
            "    100% |████████████████████████████████| 51kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas->pandarallel) (1.16.3)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas->pandarallel) (2.5.3)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->pandarallel) (2018.9)\n",
            "Requirement already satisfied: six>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pyarrow>=0.12.1->pandarallel) (1.12.0)\n",
            "Building wheels for collected packages: pandarallel\n",
            "  Building wheel for pandarallel (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/dd/ce/56/a7e16ba4f1e9e295042ed67d625c118953182a278c5fa5f51b\n",
            "Successfully built pandarallel\n",
            "Installing collected packages: pyarrow, tqdm, pandarallel\n",
            "  The script plasma_store is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "  The script tqdm is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
            "Successfully installed pandarallel-1.1.0 pyarrow-0.13.0 tqdm-4.31.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-66e0d4677ca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install h2o'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install pandarallel --user'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandarallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandarallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpandarallel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandarallel'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "imW2uNwHVTYi",
        "colab_type": "code",
        "outputId": "4e93a19e-75c2-478d-d370-4faae8b2f9f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "cell_type": "code",
      "source": [
        "#google drive os\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "os.chdir(\"drive/My Drive/Colab Notebooks/Data/FeatureEngineering\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-fe14cd988bd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/My Drive/Colab Notebooks/Data/FeatureEngineering\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/Colab Notebooks/Data/FeatureEngineering'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "p7LReH8YukqR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F6wFuAxJVW2g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from termcolor import colored\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn import metrics\n",
        "import xgboost as xgb\n",
        "\n",
        "\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JEIxKaosErI3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def df_to_h2oF(data, factor_list):\n",
        "    \n",
        "    data[factor_list] = data[factor_list].astype(int)\n",
        "    h2o_df = H2OFrame(data)\n",
        "    h2o_df[factor_list] = h2o_df[factor_list].asfactor()\n",
        "    \n",
        "    return h2o_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "67S1EvpLpbC5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def corn_process(filename):\n",
        "    data_corn = pd.read_csv(filename, index_col= 0, parse_dates=[0])\n",
        "    \n",
        "    data_corn = data_corn[~data_corn.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
        "    \n",
        "    #for renhao's purpose\n",
        "    pd.DataFrame(data_corn.index).to_csv('corn_whole_index_cleaned.csv')\n",
        "    \n",
        "    factor_list_Cap = ['Feature_57', 'Feature_58', 'Feature_45','Feature_47']\n",
        "    \n",
        "    numeric_list = list(set(data_corn.columns) - set(factor_list_Cap))\n",
        "    \n",
        "    data_corn[numeric_list] = data_corn[numeric_list].apply(lambda x: (x-np.mean(x))/np.std(x), axis = 0)\n",
        "    \n",
        "    standardized_saved_model = h2o.load_model('./leader_standardize_0424/XGBoost_1_AutoML_20190424_070314')\n",
        "    \n",
        "    standardized_corn_predict = standardized_saved_model.predict(df_to_h2oF(data_corn,factor_list_Cap))\n",
        "    \n",
        "    standardized_corn_predict_df = h2o.as_list(standardized_corn_predict)\n",
        "    \n",
        "    standardized_corn_predict_df.to_csv('standardized_corn_predict.csv')\n",
        "    \n",
        "    return standardized_corn_predict_df\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7KlkKOmbDfCN",
        "colab_type": "code",
        "outputId": "62a4f8a1-64e9-4e48-9563-48cfc6a15365",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1980
        }
      },
      "cell_type": "code",
      "source": [
        "corn_process('Report_Features_Corn.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
            "xgboost prediction progress: |████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predict</th>\n",
              "      <th>p0</th>\n",
              "      <th>p1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999829</td>\n",
              "      <td>0.000171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.998819</td>\n",
              "      <td>0.001181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999828</td>\n",
              "      <td>0.000172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999785</td>\n",
              "      <td>0.000215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.997385</td>\n",
              "      <td>0.002615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0.982586</td>\n",
              "      <td>0.017414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999438</td>\n",
              "      <td>0.000562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999082</td>\n",
              "      <td>0.000918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999805</td>\n",
              "      <td>0.000195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999827</td>\n",
              "      <td>0.000173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999965</td>\n",
              "      <td>0.000035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999894</td>\n",
              "      <td>0.000106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999957</td>\n",
              "      <td>0.000043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999920</td>\n",
              "      <td>0.000080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999876</td>\n",
              "      <td>0.000124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999926</td>\n",
              "      <td>0.000074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999904</td>\n",
              "      <td>0.000097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999954</td>\n",
              "      <td>0.000046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999911</td>\n",
              "      <td>0.000089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999899</td>\n",
              "      <td>0.000101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999927</td>\n",
              "      <td>0.000073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999941</td>\n",
              "      <td>0.000059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999905</td>\n",
              "      <td>0.000095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999470</td>\n",
              "      <td>0.000530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999748</td>\n",
              "      <td>0.000252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999924</td>\n",
              "      <td>0.000076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999962</td>\n",
              "      <td>0.000038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999879</td>\n",
              "      <td>0.000121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999596</td>\n",
              "      <td>0.000404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999961</td>\n",
              "      <td>0.000039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57077</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999912</td>\n",
              "      <td>0.000088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57078</th>\n",
              "      <td>0</td>\n",
              "      <td>0.997985</td>\n",
              "      <td>0.002015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57079</th>\n",
              "      <td>0</td>\n",
              "      <td>0.984647</td>\n",
              "      <td>0.015353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57080</th>\n",
              "      <td>0</td>\n",
              "      <td>0.981688</td>\n",
              "      <td>0.018312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57081</th>\n",
              "      <td>0</td>\n",
              "      <td>0.990950</td>\n",
              "      <td>0.009050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57082</th>\n",
              "      <td>0</td>\n",
              "      <td>0.986826</td>\n",
              "      <td>0.013174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57083</th>\n",
              "      <td>0</td>\n",
              "      <td>0.995159</td>\n",
              "      <td>0.004841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57084</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999424</td>\n",
              "      <td>0.000576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57085</th>\n",
              "      <td>0</td>\n",
              "      <td>0.997540</td>\n",
              "      <td>0.002460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57086</th>\n",
              "      <td>0</td>\n",
              "      <td>0.996982</td>\n",
              "      <td>0.003018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57087</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999060</td>\n",
              "      <td>0.000940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57088</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999517</td>\n",
              "      <td>0.000483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57089</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999859</td>\n",
              "      <td>0.000141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57090</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999351</td>\n",
              "      <td>0.000649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57091</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999477</td>\n",
              "      <td>0.000523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57092</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999872</td>\n",
              "      <td>0.000128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57093</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999089</td>\n",
              "      <td>0.000911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57094</th>\n",
              "      <td>0</td>\n",
              "      <td>0.996847</td>\n",
              "      <td>0.003153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57095</th>\n",
              "      <td>0</td>\n",
              "      <td>0.993651</td>\n",
              "      <td>0.006349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57096</th>\n",
              "      <td>0</td>\n",
              "      <td>0.773358</td>\n",
              "      <td>0.226642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57097</th>\n",
              "      <td>0</td>\n",
              "      <td>0.997226</td>\n",
              "      <td>0.002774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57098</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999813</td>\n",
              "      <td>0.000187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57099</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999635</td>\n",
              "      <td>0.000365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57100</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999617</td>\n",
              "      <td>0.000384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57101</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999656</td>\n",
              "      <td>0.000344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57102</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999890</td>\n",
              "      <td>0.000110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57103</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999827</td>\n",
              "      <td>0.000173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57104</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999481</td>\n",
              "      <td>0.000519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57105</th>\n",
              "      <td>0</td>\n",
              "      <td>0.999434</td>\n",
              "      <td>0.000566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57106</th>\n",
              "      <td>0</td>\n",
              "      <td>0.987238</td>\n",
              "      <td>0.012762</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>57107 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       predict        p0        p1\n",
              "0            0  0.999829  0.000171\n",
              "1            0  0.998819  0.001181\n",
              "2            0  0.999828  0.000172\n",
              "3            0  0.999785  0.000215\n",
              "4            0  0.997385  0.002615\n",
              "5            0  0.982586  0.017414\n",
              "6            0  0.999438  0.000562\n",
              "7            0  0.999082  0.000918\n",
              "8            0  0.999805  0.000195\n",
              "9            0  0.999827  0.000173\n",
              "10           0  0.999965  0.000035\n",
              "11           0  0.999894  0.000106\n",
              "12           0  0.999957  0.000043\n",
              "13           0  0.999920  0.000080\n",
              "14           0  0.999876  0.000124\n",
              "15           0  0.999926  0.000074\n",
              "16           0  0.999904  0.000097\n",
              "17           0  0.999954  0.000046\n",
              "18           0  0.999911  0.000089\n",
              "19           0  0.999899  0.000101\n",
              "20           0  0.999927  0.000073\n",
              "21           0  0.999941  0.000059\n",
              "22           0  0.999905  0.000095\n",
              "23           0  0.999470  0.000530\n",
              "24           0  0.999748  0.000252\n",
              "25           0  0.999924  0.000076\n",
              "26           0  0.999962  0.000038\n",
              "27           0  0.999879  0.000121\n",
              "28           0  0.999596  0.000404\n",
              "29           0  0.999961  0.000039\n",
              "...        ...       ...       ...\n",
              "57077        0  0.999912  0.000088\n",
              "57078        0  0.997985  0.002015\n",
              "57079        0  0.984647  0.015353\n",
              "57080        0  0.981688  0.018312\n",
              "57081        0  0.990950  0.009050\n",
              "57082        0  0.986826  0.013174\n",
              "57083        0  0.995159  0.004841\n",
              "57084        0  0.999424  0.000576\n",
              "57085        0  0.997540  0.002460\n",
              "57086        0  0.996982  0.003018\n",
              "57087        0  0.999060  0.000940\n",
              "57088        0  0.999517  0.000483\n",
              "57089        0  0.999859  0.000141\n",
              "57090        0  0.999351  0.000649\n",
              "57091        0  0.999477  0.000523\n",
              "57092        0  0.999872  0.000128\n",
              "57093        0  0.999089  0.000911\n",
              "57094        0  0.996847  0.003153\n",
              "57095        0  0.993651  0.006349\n",
              "57096        0  0.773358  0.226642\n",
              "57097        0  0.997226  0.002774\n",
              "57098        0  0.999813  0.000187\n",
              "57099        0  0.999635  0.000365\n",
              "57100        0  0.999617  0.000384\n",
              "57101        0  0.999656  0.000344\n",
              "57102        0  0.999890  0.000110\n",
              "57103        0  0.999827  0.000173\n",
              "57104        0  0.999481  0.000519\n",
              "57105        0  0.999434  0.000566\n",
              "57106        0  0.987238  0.012762\n",
              "\n",
              "[57107 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "4Zomm2PWVnvL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def es_process(filename, no_of_models, debug = False):\n",
        "               \n",
        "    data = pd.read_csv(filename, index_col= 0, parse_dates=[0])\n",
        "    remove_data = data[~data.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
        "    factor_list_es = ['feature_57', 'feature_58', 'Feature_45','Feature_47', 'Target']\n",
        "    numeric_list_es = list(set(remove_data.columns) - set(factor_list_es))\n",
        "    remove_data[numeric_list_es] = remove_data[numeric_list_es].apply(lambda x: (x-np.mean(x))/np.std(x), axis = 0)\n",
        "    #true label\n",
        "    X = remove_data.iloc[:,:-1]\n",
        "    y = remove_data['Target']\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, shuffle=False)\n",
        "    #for Ren Hao's usage\n",
        "    #pd.DataFrame(X_train.index).to_csv('cleaned_train_index.csv')\n",
        "    #pd.DataFrame(X_test.index).to_csv('cleaned_test_index.csv')\n",
        "    sm = SMOTE(ratio = 'minority')\n",
        "    X_resampled, y_resampled = sm.fit_sample(X= np.nan_to_num(X_train), y = np.nan_to_num(y_train))\n",
        "    #X_resampled, y_resampled = X_train, y_train\n",
        "    from h2o.automl import H2OAutoML\n",
        "    import h2o\n",
        "    from h2o.frame import H2OFrame\n",
        "    h2o.init()\n",
        "    df = remove_data.copy(deep = True)\n",
        "    h2o_df = df_to_h2oF(df, factor_list_es)\n",
        "    \n",
        "    train_tmp, test_tmp = train_test_split(remove_data, test_size = 1/3, shuffle = False)\n",
        "    train_h2o =  df_to_h2oF(train_tmp, factor_list_es)\n",
        "    test_h2o = df_to_h2oF(test_tmp, factor_list_es)\n",
        "   \n",
        "    test_h2o_to_aml = test_h2o #save for test \n",
        "    train_h2o_resample_df = pd.concat([pd.DataFrame(X_resampled), pd.DataFrame(y_resampled)], axis = 1 )\n",
        "    train_h2o_resample_df.columns = df.columns\n",
        "    train_h2o_resample_h2oframe = df_to_h2oF(train_h2o_resample_df, factor_list_es)\n",
        "    #training\n",
        "    x = train_h2o_resample_h2oframe.columns\n",
        "    y = 'Target'\n",
        "    x.remove(y)\n",
        "    if debug == True:\n",
        "        aml = H2OAutoML(max_models=3, seed=610)\n",
        "        aml.train(x=x, y=y, training_frame=train_h2o_resample_h2oframe)\n",
        "    else:\n",
        "        aml = H2OAutoML(max_models = no_of_models, seed = 610)\n",
        "        aml.train(x=x, y=y, training_frame=train_h2o_resample_h2oframe)\n",
        "    lb = aml.leaderboard\n",
        "    print(lb)\n",
        "    model_path = h2o.save_model(model=aml.leader, path=\"./buNeng_shuffle\", force=True)\n",
        "    \n",
        "    # Get model ids for all models in the AutoML Leaderboard\n",
        "    model_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n",
        "    # Get the \"All Models\" Stacked Ensemble model\n",
        "    se = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\n",
        "    # Get the Stacked Ensemble metalearner model\n",
        "    metalearner = h2o.get_model(se.metalearner()['name'])\n",
        "    \n",
        "    \n",
        "    preds_standardize = aml.leader.predict(df_to_h2oF(h2o.as_list(test_h2o_to_aml).iloc[:, :-1], factor_list[:-1]))\n",
        "    feature_importance = standardized_saved_model.varimp(use_pandas=True)\n",
        "    feature_importance.to_csv('feature_importance_xgb.csv')\n",
        "    standardized_saved_model.varimp_plot()\n",
        "    test_h2o_pandas = h2o.as_list(test_h2o)\n",
        "    #y_pred = xgb_model.predict(X_test.as_matrix())\n",
        "\n",
        "    cm = confusion_matrix(test_h2o_pandas['Target'].values, (h2o.as_list(preds_standardize)['predict']>0.5))\n",
        "    print(colored('The Confusion Matrix is: ', 'red'),'\\n', cm)\n",
        "    # Calculate the accuracy on test set\n",
        "    predict_accuracy_on_test_set = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])\n",
        "    print(colored('The Accuracy on Test Set is: ', 'blue'), colored(predict_accuracy_on_test_set, 'blue'))\n",
        "    \n",
        "    print(metrics.classification_report(y_true=test_h2o_pandas['Target'].values, y_pred=(h2o.as_list(preds_standardize)['predict']>0.5).astype(float)))\n",
        "    \n",
        "    return model_ids, se, metalearner\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ZzDpEL2lNIs",
        "colab_type": "code",
        "outputId": "e6fa3182-818f-440f-d853-f2395d61a2fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1572
        }
      },
      "cell_type": "code",
      "source": [
        "model_ids, se, metalearner = es_process('Report_Features.csv',no_of_models =10, debug = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
              "<td>7 hours 29 mins</td></tr>\n",
              "<tr><td>H2O cluster timezone:</td>\n",
              "<td>Etc/UTC</td></tr>\n",
              "<tr><td>H2O data parsing timezone:</td>\n",
              "<td>UTC</td></tr>\n",
              "<tr><td>H2O cluster version:</td>\n",
              "<td>3.24.0.2</td></tr>\n",
              "<tr><td>H2O cluster version age:</td>\n",
              "<td>8 days </td></tr>\n",
              "<tr><td>H2O cluster name:</td>\n",
              "<td>H2O_from_python_unknownUser_kr6n3o</td></tr>\n",
              "<tr><td>H2O cluster total nodes:</td>\n",
              "<td>1</td></tr>\n",
              "<tr><td>H2O cluster free memory:</td>\n",
              "<td>2.191 Gb</td></tr>\n",
              "<tr><td>H2O cluster total cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O cluster allowed cores:</td>\n",
              "<td>2</td></tr>\n",
              "<tr><td>H2O cluster status:</td>\n",
              "<td>locked, healthy</td></tr>\n",
              "<tr><td>H2O connection url:</td>\n",
              "<td>http://localhost:54321</td></tr>\n",
              "<tr><td>H2O connection proxy:</td>\n",
              "<td>None</td></tr>\n",
              "<tr><td>H2O internal security:</td>\n",
              "<td>False</td></tr>\n",
              "<tr><td>H2O API Extensions:</td>\n",
              "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
              "<tr><td>Python version:</td>\n",
              "<td>3.6.7 final</td></tr></table></div>"
            ],
            "text/plain": [
              "--------------------------  ---------------------------------------------------\n",
              "H2O cluster uptime:         7 hours 29 mins\n",
              "H2O cluster timezone:       Etc/UTC\n",
              "H2O data parsing timezone:  UTC\n",
              "H2O cluster version:        3.24.0.2\n",
              "H2O cluster version age:    8 days\n",
              "H2O cluster name:           H2O_from_python_unknownUser_kr6n3o\n",
              "H2O cluster total nodes:    1\n",
              "H2O cluster free memory:    2.191 Gb\n",
              "H2O cluster total cores:    2\n",
              "H2O cluster allowed cores:  2\n",
              "H2O cluster status:         locked, healthy\n",
              "H2O connection url:         http://localhost:54321\n",
              "H2O connection proxy:\n",
              "H2O internal security:      False\n",
              "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4\n",
              "Python version:             3.6.7 final\n",
              "--------------------------  ---------------------------------------------------"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
            "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table>\n",
              "<thead>\n",
              "<tr><th>model_id                                           </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">   logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">     rmse</th><th style=\"text-align: right;\">       mse</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>XGBoost_1_AutoML_20190425_015417                   </td><td style=\"text-align: right;\">0.999993</td><td style=\"text-align: right;\">0.00661999</td><td style=\"text-align: right;\">           0.000977064</td><td style=\"text-align: right;\">0.040217 </td><td style=\"text-align: right;\">0.0016174 </td></tr>\n",
              "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190425_015417</td><td style=\"text-align: right;\">0.999992</td><td style=\"text-align: right;\">0.0109476 </td><td style=\"text-align: right;\">           0.000977064</td><td style=\"text-align: right;\">0.0413069</td><td style=\"text-align: right;\">0.00170626</td></tr>\n",
              "<tr><td>StackedEnsemble_AllModels_AutoML_20190425_015417   </td><td style=\"text-align: right;\">0.999862</td><td style=\"text-align: right;\">0.0109711 </td><td style=\"text-align: right;\">           0.00155474 </td><td style=\"text-align: right;\">0.0444862</td><td style=\"text-align: right;\">0.00197902</td></tr>\n",
              "<tr><td>XGBoost_2_AutoML_20190425_015417                   </td><td style=\"text-align: right;\">0.998992</td><td style=\"text-align: right;\">0.133179  </td><td style=\"text-align: right;\">           0.00672534 </td><td style=\"text-align: right;\">0.142596 </td><td style=\"text-align: right;\">0.0203337 </td></tr>\n",
              "</tbody>\n",
              "</table>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
            "xgboost prediction progress: |████████████████████████████████████████████| 100%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2MAAAJTCAYAAACFPM4QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv3LbZaEZVGoLAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1008x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The Confusion Matrix is:  \n",
            " [[34764   217]\n",
            " [  133    86]]\n",
            "The Accuracy on Test Set is:  0.9900568181818182\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     34981\n",
            "           1       0.28      0.39      0.33       219\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     35200\n",
            "   macro avg       0.64      0.69      0.66     35200\n",
            "weighted avg       0.99      0.99      0.99     35200\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-37d354310432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetalearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mes_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Report_Features.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mno_of_models\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "1KvWUVLxbWKw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eDOZQksqE1Wo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "''' code that do not work for now\n",
        "numeric_transformer = Pipeline(steps = [('scaler',StandardScaler())])\n",
        "preprocessor = ColumnTransformer(\n",
        "transformers = [('num', numeric_transformer, numeric_list)])\n",
        "data[numeric_list] = preprocessor.fit_transform(data[numeric_list])\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5Oe2rlp5H9bD",
        "colab_type": "code",
        "outputId": "e5b4f916-d11e-464a-a6e8-43c4fa840faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "aml.leaderboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
            "This H2OFrame is empty.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "metadata": {
        "id": "YtwPltOV06Qd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_es_with_saved_model(filename):\n",
        "  \n",
        "    data_es = pd.read_csv(filename, index_col= 0, parse_dates=[0])\n",
        "    standardized_saved_model = h2o.load_model('./leader_standardize_0424/XGBoost_1_AutoML_20190424_070314')\n",
        "    \n",
        "    #true label\n",
        "    X = remove_data.iloc[:,:-1]\n",
        "    y = remove_data['Target']\n",
        "    import warnings\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1/3, shuffle=False)\n",
        "    \n",
        "    #for Ren Hao's usage\n",
        "    pd.DataFrame(X_train.index).to_csv('cleaned_train_index_es.csv')\n",
        "    pd.DataFrame(X_test.index).to_csv('cleaned_test_index_es.csv')\n",
        "    \n",
        "    remove_data =  data_es[~data_es.isin([np.nan, np.inf, -np.inf]).any(1)]\n",
        "    factor_list_es = ['feature_57', 'feature_58', 'Feature_45','Feature_47', 'Target']\n",
        "    numeric_list_es = list(set(remove_data.columns) - set(factor_list_es))\n",
        "    remove_data[numeric_list_es] = remove_data[numeric_list_es].apply(lambda x: (x-np.mean(x))/np.std(x), axis = 0)\n",
        "    \n",
        "    \n",
        "    df = remove_data.copy(deep = True)\n",
        "    h2o_df = df_to_h2oF(df, factor_list_es)\n",
        "    \n",
        "    train_h2o, test_h2o = h2o_df.split_frame(ratios = [2/3], seed = 610)\n",
        "    \n",
        "    preds_standardize = aml.leader.predict(df_to_h2oF(h2o.as_list(test_h2o).iloc[:, :-1], factor_list[:-1]))\n",
        "    \n",
        "    \n",
        "    standardized_corn_predict_df.to_csv('standardized_corn_predict.csv')\n",
        "    \n",
        "    cm = confusion_matrix(test_h2o_pandas['Target'].values, (h2o.as_list(preds_standardize)['predict']>0.5))\n",
        "    \n",
        "    \n",
        "    print(colored('The Confusion Matrix is: ', 'red'),'\\n', cm)\n",
        "    predict_accuracy_on_test_set = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])\n",
        "    print(colored('The Accuracy on Test Set is: ', 'blue'), colored(predict_accuracy_on_test_set, 'blue'))\n",
        "    \n",
        "    print(metrics.classification_report(y_true=test_h2o_pandas['Target'].values, y_pred=(h2o.as_list(preds_standardize)['predict']>0.5).astype(float)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZUbNlaH05xWo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cI-tkOl66QXz",
        "colab_type": "code",
        "outputId": "f8783fa1-03bc-405a-fc02-88f6306c1e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "cell_type": "code",
      "source": [
        "#y_pred = xgb_model.predict(X_test.as_matrix())\n",
        "\n",
        "cm = confusion_matrix(test_h2o_pandas['Target'].values, (h2o.as_list(preds_standardize)['predict']>0.5))\n",
        "print(colored('The Confusion Matrix is: ', 'red'),'\\n', cm)\n",
        "# Calculate the accuracy on test set\n",
        "predict_accuracy_on_test_set = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])\n",
        "print(colored('The Accuracy on Test Set is: ', 'blue'), colored(predict_accuracy_on_test_set, 'blue'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-bfd413963295>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_h2o_pandas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_standardize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolored\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The Confusion Matrix is: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'red'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Calculate the accuracy on test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredict_accuracy_on_test_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_h2o_pandas' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "HQo-yvBE6QU7",
        "colab_type": "code",
        "outputId": "fc0ed760-cde3-48d8-d443-a8e9814ec918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(y_true=test_h2o_pandas['Target'].values, y_pred=(h2o.as_list(preds_standardize)['predict']>0.5).astype(float)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-2334cd05db80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_h2o_pandas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_standardize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_h2o_pandas' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "b-W3rPfCXEqO",
        "colab_type": "code",
        "outputId": "400f9fe0-03c2-4a77-9e7f-836f486faf51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "#y_pred = xgb_model.predict(X_test.as_matrix())\n",
        "\n",
        "cm = confusion_matrix(test_h2o_pandas['Target'].values, (preds_pandas['predict']>0.5))\n",
        "print(colored('The Confusion Matrix is: ', 'red'),'\\n', cm)\n",
        "# Calculate the accuracy on test set\n",
        "predict_accuracy_on_test_set = (cm[0,0] + cm[1,1])/(cm[0,0] + cm[1,1]+cm[1,0] + cm[0,1])\n",
        "print(colored('The Accuracy on Test Set is: ', 'blue'), colored(predict_accuracy_on_test_set, 'blue'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Confusion Matrix is:  \n",
            " [[34843    69]\n",
            " [   49   123]]\n",
            "The Accuracy on Test Set is:  0.9966366434842093\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x5Je52XPXFym",
        "colab_type": "code",
        "outputId": "83968ba9-2216-4d32-899b-9271e24b648e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "cell_type": "code",
      "source": [
        "print(metrics.classification_report(y_true=test_h2o_pandas['Target'].values, y_pred=(preds_pandas['predict'] > 0.5).astype(float)))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     34912\n",
            "           1       0.64      0.72      0.68       172\n",
            "\n",
            "   micro avg       1.00      1.00      1.00     35084\n",
            "   macro avg       0.82      0.86      0.84     35084\n",
            "weighted avg       1.00      1.00      1.00     35084\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}