{"cells":[{"metadata":{"_cell_guid":"224f05d5-03d7-5622-804c-2ec2fbbdba24"},"cell_type":"markdown","source":"#**Hey Kagglers, this notebook will go over a couple of basic Natural Language Processing techniques using the [scikit-learn](http://scikit-learn.org/stable/) library. Special thanks to [Aaron7sun](https://www.kaggle.com/aaron7sun) for providing the [dataset](https://www.kaggle.com/aaron7sun/stocknews) and \"assignment\" for us to do!**  \n#Thanks for reading and feel free to leave feedback. I'd like to make more tutorial notebooks like this, so let me know if you think there is anything I could improve."},{"metadata":{"_cell_guid":"0c26a06e-66cd-e955-edd9-a0645bf64795"},"cell_type":"markdown","source":"----------"},{"metadata":{"_cell_guid":"097e4b27-d3d4-72bf-954d-ca31aa060438"},"cell_type":"markdown","source":"# Notebook Prep"},{"metadata":{"_cell_guid":"6dbbf81e-cab9-5824-9552-72d3c8e20c51"},"cell_type":"markdown","source":"First things first, let's import the libraries we'll be using.  "},{"metadata":{"_cell_guid":"70ceca1b-8563-1894-1334-80ffb120f778","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression","execution_count":1,"outputs":[]},{"metadata":{"_cell_guid":"dcf16f8f-8c77-e21f-7ad9-9428dfb1e0e6"},"cell_type":"markdown","source":"[Pandas](http://pandas.pydata.org/) will make our data easy to look at and work with.  \n[CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), part of scikit-learn, will take care of our NLP tasks.  \n[LogisticRegression](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html), also part of scikit-learn, will train and test our predictive models."},{"metadata":{"_cell_guid":"6ac9d751-e8f5-8940-ac71-426f10e0bd04"},"cell_type":"markdown","source":"----------"},{"metadata":{"_cell_guid":"f9e5522e-37ef-b384-11e9-42f9895d423c"},"cell_type":"markdown","source":"# Data Import"},{"metadata":{"_cell_guid":"9add28d0-c500-943e-64a8-48c8a131b6d0"},"cell_type":"markdown","source":"Now, let's [read](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) in the data with Pandas.  \nIf you're working in something other than a Kaggle notebook, be sure to change the file location.  \nFor this tutorial, we're just going to use the combined dataset that Aaron prepared for us, but you're welcome to import the other two CSV files if you want to combine them in a different way."},{"metadata":{"_cell_guid":"6da1c746-e849-fa5b-b0b6-4137586b533e","trusted":true},"cell_type":"code","source":"data = pd.read_csv('../input/Combined_News_DJIA.csv',parse_dates=[0])","execution_count":6,"outputs":[]},{"metadata":{"_cell_guid":"228f34e9-9628-bddc-a78a-24adf933644b"},"cell_type":"markdown","source":"Next, let's take a look at the data with the [head](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.head.html) method."},{"metadata":{"_cell_guid":"01834ef5-43f9-7456-7a7d-c3194dd8f71a","trusted":true},"cell_type":"code","source":"data['Date'].max()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"Timestamp('2016-07-01 00:00:00')"},"metadata":{}}]},{"metadata":{"_cell_guid":"4987908b-e98c-7c20-6c11-023f1bb03883"},"cell_type":"markdown","source":"We've got a lot of vaiables here, but the layout is pretty straight-forward.  \nAs a reminder, the Label variable will be a **1** if the DJIA **stayed the same or rose** on that date or \n **0** if the DJIA **fell** on that date."},{"metadata":{"_cell_guid":"30295018-7927-3c30-1b50-eb982fa3266e"},"cell_type":"markdown","source":"And finally, before we get started on the rest of the notebook, we need to split our data into a training set and a testing set. Per Aaron's instructions, we'll use all of the dates up to the end of 2014 as our training data and everything after as testing data."},{"metadata":{"_cell_guid":"b79d88e9-136b-c6c8-0ebb-cc564e24c26e","trusted":true},"cell_type":"code","source":"train = data[data['Date'] < '2015-01-01']\ntest = data[data['Date'] > '2014-12-31']","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"6ae3f526-4148-0146-1964-9688eb9b08f1"},"cell_type":"markdown","source":"----------"},{"metadata":{"_cell_guid":"ed38998a-6e7a-aa1c-fa3a-147245aacb5b"},"cell_type":"markdown","source":"# Text Preprocessing"},{"metadata":{"_cell_guid":"a5bb5d3e-99d6-3485-d30b-9a638ea5f75f"},"cell_type":"markdown","source":"Now that our data is loaded in, we need to clean it up just a little bit to prepare it for the rest of our analysis.  \nTo illustrate this process, look at how the example headline below changes from cell to cell.  \nDon't worry about the code too much here, since this example is only meant to be visual."},{"metadata":{"_cell_guid":"1a57d931-abd1-fc84-656c-6dcb7136fbe6","trusted":true},"cell_type":"code","source":"example = train.iloc[3,10]\nprint(example)","execution_count":12,"outputs":[{"output_type":"stream","text":"b\"The commander of a Navy air reconnaissance squadron that provides the President and the defense secretary the airborne ability to command the nation's nuclear weapons has been relieved of duty\"\n","name":"stdout"}]},{"metadata":{"_cell_guid":"3cadd198-2b2d-bbf0-1c29-f15b2eee829d","trusted":true},"cell_type":"code","source":"example2 = example.lower()\nprint(example2)","execution_count":13,"outputs":[{"output_type":"stream","text":"b\"the commander of a navy air reconnaissance squadron that provides the president and the defense secretary the airborne ability to command the nation's nuclear weapons has been relieved of duty\"\n","name":"stdout"}]},{"metadata":{"_cell_guid":"4aa5b173-9021-e490-790f-1b00a2b31cb7","trusted":true},"cell_type":"code","source":"example3 = CountVectorizer().build_tokenizer()(example2)\nprint(example3)","execution_count":14,"outputs":[{"output_type":"stream","text":"['the', 'commander', 'of', 'navy', 'air', 'reconnaissance', 'squadron', 'that', 'provides', 'the', 'president', 'and', 'the', 'defense', 'secretary', 'the', 'airborne', 'ability', 'to', 'command', 'the', 'nation', 'nuclear', 'weapons', 'has', 'been', 'relieved', 'of', 'duty']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"9cb20699-bef3-1a23-f46d-1f863dd3c00b","trusted":true},"cell_type":"code","source":"pd.DataFrame([[x,example3.count(x)] for x in set(example3)], columns = ['Word', 'Count'])","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"              Word  Count\n0         squadron      1\n1         provides      1\n2             duty      1\n3        commander      1\n4              the      5\n5          weapons      1\n6              air      1\n7               to      1\n8             navy      1\n9        secretary      1\n10         command      1\n11         defense      1\n12        airborne      1\n13         ability      1\n14       president      1\n15  reconnaissance      1\n16         nuclear      1\n17             and      1\n18        relieved      1\n19          nation      1\n20              of      2\n21            been      1\n22            that      1\n23             has      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>squadron</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>provides</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>duty</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>commander</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>the</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>weapons</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>air</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>to</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>navy</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>secretary</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>command</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>defense</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>airborne</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>ability</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>president</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>reconnaissance</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>nuclear</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>and</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>relieved</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>nation</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>of</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>been</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>that</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>has</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"4c824f61-f8a5-66d6-f1a7-cff3b64c4190"},"cell_type":"markdown","source":"Were you able to see everything that changed?  \nThe process involved:  \n- Converting the headline to lowercase letters  \n- Splitting the sentence into a list of words  \n- Removing punctuation and meaningless words  \n- Transforming that list into a table of counts"},{"metadata":{"_cell_guid":"4663088a-e834-2512-1f87-ca768f49ae2c"},"cell_type":"markdown","source":"What started as a relatively \"messy\" sentence has now become an neatly organized table!  \nAnd while this may not be exactly what goes on behind the scenes with scikit-learn, this example should give you a pretty good idea about how it works."},{"metadata":{"_cell_guid":"4ec409c9-443f-56eb-5194-63b6db6ee00f"},"cell_type":"markdown","source":"So now that you've seen what the text processing looks like, let's get started on the fun part, modeling!"},{"metadata":{"_cell_guid":"d142f2bc-f61e-4829-4c13-6da37345eea6"},"cell_type":"markdown","source":"----------"},{"metadata":{"_cell_guid":"cc8aa11c-93cd-1c4b-bf03-21b20a652ecc"},"cell_type":"markdown","source":"# Basic Model Training and Testing"},{"metadata":{"_cell_guid":"adcff1c8-9d37-4329-aaeb-6a5a7ac6a53d"},"cell_type":"markdown","source":"As mentioned previously, scikit-learn is going to take care of all of our preprocessing needs.  \nThe tool we'll be using is CountVectorizer, which takes a single list of strings as input, and produces word counts for each one."},{"metadata":{"_cell_guid":"2119fab1-da05-c807-85bb-247a0f378363"},"cell_type":"markdown","source":"You might be wondering if our dataframe meets this \"single list of strings\" criteria, and the answer to that is... it doesn't!  \nIn order to meet this criteria, we'll use the following [for loop](https://wiki.python.org/moin/ForLoop) to iterate through each row of our dataset, [combine](https://docs.python.org/3.5/library/stdtypes.html#str.join) all of our headlines into a single string, then [add](https://docs.python.org/3.5/tutorial/datastructures.html) that string to the list we need for CountVectorizer."},{"metadata":{"_cell_guid":"3c8ed1f2-2dcf-1015-05b7-edfb95773b4e","trusted":true},"cell_type":"code","source":"trainheadlines = []\nfor row in range(0,len(train.index)):\n    trainheadlines.append(' '.join(str(x) for x in train.iloc[row,2:27]))","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainheadlines[:5]","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"['b\"Georgia \\'downs two Russian warplanes\\' as countries move to brink of war\" b\\'BREAKING: Musharraf to be impeached.\\' b\\'Russia Today: Columns of troops roll into South Ossetia; footage from fighting (YouTube)\\' b\\'Russian tanks are moving towards the capital of South Ossetia, which has reportedly been completely destroyed by Georgian artillery fire\\' b\"Afghan children raped with \\'impunity,\\' U.N. official says - this is sick, a three year old was raped and they do nothing\" b\\'150 Russian tanks have entered South Ossetia whilst Georgia shoots down two Russian jets.\\' b\"Breaking: Georgia invades South Ossetia, Russia warned it would intervene on SO\\'s side\" b\"The \\'enemy combatent\\' trials are nothing but a sham: Salim Haman has been sentenced to 5 1/2 years, but will be kept longer anyway just because they feel like it.\" b\\'Georgian troops retreat from S. Osettain capital, presumably leaving several hundred people killed. [VIDEO]\\' b\\'Did the U.S. Prep Georgia for War with Russia?\\' b\\'Rice Gives Green Light for Israel to Attack Iran: Says U.S. has no veto over Israeli military ops\\' b\\'Announcing:Class Action Lawsuit on Behalf of American Public Against the FBI\\' b\"So---Russia and Georgia are at war and the NYT\\'s top story is opening ceremonies of the Olympics?  What a fucking disgrace and yet further proof of the decline of journalism.\" b\"China tells Bush to stay out of other countries\\' affairs\" b\\'Did World War III start today?\\' b\\'Georgia Invades South Ossetia - if Russia gets involved, will NATO absorb Georgia and unleash a full scale war?\\' b\\'Al-Qaeda Faces Islamist Backlash\\' b\\'Condoleezza Rice: \"The US would not act to prevent an Israeli strike on Iran.\" Israeli Defense Minister Ehud Barak: \"Israel is prepared for uncompromising victory in the case of military hostilities.\"\\' b\\'This is a busy day:  The European Union has approved new sanctions against Iran in protest at its nuclear programme.\\' b\"Georgia will withdraw 1,000 soldiers from Iraq to help fight off Russian forces in Georgia\\'s breakaway region of South Ossetia\" b\\'Why the Pentagon Thinks Attacking Iran is a Bad Idea - US News &amp; World Report\\' b\\'Caucasus in crisis: Georgia invades South Ossetia\\' b\\'Indian shoe manufactory  - And again in a series of \"you do not like your work?\"\\' b\\'Visitors Suffering from Mental Illnesses Banned from Olympics\\' b\"No Help for Mexico\\'s Kidnapping Surge\"',\n 'b\\'Why wont America and Nato help us? If they wont help us now, why did we help them in Iraq?\\' b\\'Bush puts foot down on Georgian conflict\\' b\"Jewish Georgian minister: Thanks to Israeli training, we\\'re fending off Russia \" b\\'Georgian army flees in disarray as Russians advance - Gori abandoned to Russia without a shot fired\\' b\"Olympic opening ceremony fireworks \\'faked\\'\" b\\'What were the Mossad with fraudulent New Zealand Passports doing in Iraq?\\' b\\'Russia angered by Israeli military sale to Georgia\\' b\\'An American citizen living in S.Ossetia blames U.S. and Georgian leaders for the genocide of innocent people\\' b\\'Welcome To World War IV! Now In High Definition!\\' b\"Georgia\\'s move, a mistake of monumental proportions \" b\\'Russia presses deeper into Georgia; U.S. says regime change is goal\\' b\\'Abhinav Bindra wins first ever Individual Olympic Gold Medal for India\\' b\\' U.S. ship heads for Arctic to define territory\\' b\\'Drivers in a Jerusalem taxi station threaten to quit rather than work for their new boss - an Arab\\' b\\'The French Team is Stunned by Phelps and the 4x100m Relay Team\\' b\\'Israel and the US behind the Georgian aggression?\\' b\\'\"Do not believe TV, neither Russian nor Georgian. There are much more victims\"\\' b\\'Riots are still going on in Montreal (Canada) because police murdered a boy on Saturday.\\' b\\'China to overtake US as largest manufacturer\\' b\\'War in South Ossetia [PICS]\\' b\\'Israeli Physicians Group Condemns State Torture\\' b\\' Russia has just beaten the United States over the head with Peak Oil\\' b\\'Perhaps *the* question about the Georgia - Russia conflict \\' b\\'Russia is so much better at war\\' b\"So this is what it\\'s come to: trading sex for food.\"',\n 'b\\'Remember that adorable 9-year-old who sang at the opening ceremonies? That was fake, too.\\' b\"Russia \\'ends Georgia operation\\'\" b\\'\"If we had no sexual harassment we would have no children...\"\\' b\"Al-Qa\\'eda is losing support in Iraq because of a brutal crackdown on activities it regards as un-Islamic - including women buying cucumbers\" b\\'Ceasefire in Georgia: Putin Outmaneuvers the West\\' b\\'Why Microsoft and Intel tried to kill the XO $100 laptop\\' b\\'Stratfor: The Russo-Georgian War and the Balance of Power   \\' b\"I\\'m Trying to Get a Sense of This Whole Georgia-Russia War: Vote Up If You Think Georgia Started It, Or Down If you Think Russia Did\" b\"The US military was surprised by the timing and swiftness of the Russian military\\'s move into South Ossetia and is still trying to sort out what happened, a US defense official said Monday\" b\\'U.S. Beats War Drum as Iran Dumps the Dollar\\' b\\'Gorbachev: \"Georgian military attacked the South Ossetian capital of Tskhinvali with multiple rocket launchers designed to devastate large areas\"\\' b\\'CNN use footage of Tskhinvali ruins to cover Georgian report [VIDEO]\\' b\\'Beginning a war as the Olympics were opening violates the ancient tradition of a truce to conflict during the Games.  The IOC could respond by taking the 2014 games away from Russia.\\' b\\'55 pyramids as large as the Luxor stacked into a mega-city pyramid in Tokyo Bay\\' b\\'The 11 Top Party Cities in the World\\' b\\'U.S. troops still in Georgia (did you know they were in Georgia in the first place?)\\' b\\'Why Russias response to Georgia was right\\' b\\'Gorbachev accuses U.S. of making a \"serious blunder\" in pursuing its interest in the Caucasus region\\' b\\'Russia, Georgia, and NATO: Cold War Two\\' b\\'Remember that adorable 62-year-old who led your country into war based on evidence? That was fake, too.\\' b\\'War in Georgia: The Israeli connection\\' b\\'All signs point to the US encouraging Georgia to invade South Ossetia. Goddamnit Bush.\\' b\\'Christopher King argues that the US and NATO are behind the Georgian invasion of South Ossetia but have misjudged Russian resolve. \\' b\\'America: The New Mexico?\\' b\"BBC NEWS | Asia-Pacific | Extinction \\'by man not climate\\'\"',\n 'b\\' U.S. refuses Israel weapons to attack Iran: report\\' b\"When the president ordered to attack Tskhinvali [the capital of South Ossetia], we knew then we were doomed. How come he didn\\'t realize that?\" b\\' Israel clears troops who killed Reuters cameraman\\' b\\'Britain\\\\\\'s policy of being tough on drugs is \"pointless\", says a former civil servant who once ran the Cabinet\\\\\\'s anti-drugs unit.\\' b\\'Body of 14 year old found in trunk; Latest (ransom paid) kidnapping victim in Mexico. Head cop quits, Prez dissolves suspect elite task force\\' b\\'China has moved 10 *million* quake survivors into prefab homes\\' b\"Bush announces Operation Get All Up In Russia\\'s Grill. Yeah, this will end well.\" b\\'Russian forces sink Georgian ships \\' b\"The commander of a Navy air reconnaissance squadron that provides the President and the defense secretary the airborne ability to command the nation\\'s nuclear weapons has been relieved of duty\" b\"92% of CNN readers: Russia\\'s actions in Georgia - justified!\" b\\'USA to send fleet into Black Sea to help Georgia, send troops in \"humanitarian aid exercise\"\\' b\"US warns against Israeli plan to strike against Iran\\'s nuclear facilities\" b\"In an intriguing cyberalliance, two Estonian computer experts are heading to Georgia to keep the country\\'s networks running amid an intense military confrontation with Russia\" b\\'The CNN Effect: Georgia Schools Russia in Information Warfare\\' b\\'Why Russias response to Georgia was right\\' b\\'Elephants extinct by 2020?\\' b\\'US humanitarian missions soon in Georgia - if Russia hits the US - WWIII?\\' b\"Georgia\\'s DDOS came from US sources\" b\\'Russian convoy heads into Georgia, violating truce\\' b\\'Israeli defence minister: US against strike on Iran\\' b\\'Gorbachev: We Had No Choice\\' b\\'Witness: Russian forces head towards Tbilisi in breach of ceasefire agreement\\' b\\' Quarter of Russians blame U.S. for conflict: poll\\' b\\'Georgian president  says US military will take control of seaports and airports - Pentagon denies\\' b\\'2006: Nobel laureate Aleksander Solzhenitsyn accuses U.S., NATO of encircling Russia\\'',\n 'b\\'All the experts admit that we should legalise drugs \\' b\\'War in South Osetia - 89 pictures made by a Russian soldier.\\' b\\'Swedish wrestler Ara Abrahamian throws away medal in Olympic hissy fit \\' b\\'Russia exaggerated the death toll in South Ossetia. Now only 44 were originally killed compared to 2,000.\\' b\\'Missile That Killed 9 Inside Pakistan May Have Been Launched by the CIA\\' b\"Rushdie Condemns Random House\\'s Refusal to Publish Novel for Fear of Muslim Retaliation\" b\\'Poland and US agree to missle defense deal. Interesting timing!\\' b\\'Will the Russians conquer Tblisi? Bet on it, no seriously you can BET on it\\' b\\'Russia exaggerating South Ossetian death toll, says human rights group\\' b\\' Musharraf expected to resign rather than face impeachment\\' b\\'Moscow Made Plans Months Ago to Invade Georgia\\' b\\'Why Russias response to Georgia was right\\' b\\'Nigeria has handed over the potentially oil-rich Bakassi peninsula to Cameroon.\\' b\\'The US and Poland have agreed a preliminary deal on plans for the controversial US defence shield\\' b\\'Russia apparently is sabotaging infrastructure to cripple the already battered Georgian military.\\' b\\'Bank analyst forecast Georgian crisis 2 days early\\' b\"Georgia confict could set back Russia\\'s US relations \\'for years\\' | World news | guardian.co.uk\" b\\'War in the Caucasus is as much the product of an American imperial drive as local conflicts.\\' b\\'\"Non-media\" photos of South Ossetia/Georgia conflict.\\' b\\'Georgian TV reporter shot by Russian sniper during live broadcast [video]\\' b\\'Saudi Arabia: Mother moves to block child marriage\\' b\\'Taliban wages war on humanitarian aid workers\\' b\\'Russia: World  \"can forget about\" Georgia\\\\\\'s territorial integrity\\' b\\'Darfur rebels accuse Sudan of mounting major attack\\' b\\'Philippines : Peace Advocate say Muslims need assurance Christians not out to convert them\\'']"},"metadata":{}}]},{"metadata":{"_cell_guid":"edfbef25-8c6b-5e78-aac5-f9f47df72f25"},"cell_type":"markdown","source":"With our headlines formatted, we can set up our CountVectorizer.  \nTo start, let's just use the default settings and see how it goes!  \nBelow, we'll name our default vectorizer, then [use](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform) it on our list of combined headlines.  \nAfter that, we'll take a look at the size of the result to see how many words we have."},{"metadata":{"_cell_guid":"18f44a5c-3f39-5ce4-5f0b-9aa86ac29f5d","trusted":true},"cell_type":"code","source":"basicvectorizer = CountVectorizer()\nbasictrain = basicvectorizer.fit_transform(trainheadlines)\nprint(basictrain.shape)","execution_count":17,"outputs":[{"output_type":"stream","text":"(1611, 31675)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"basictrain","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"<1611x31675 sparse matrix of type '<class 'numpy.int64'>'\n\twith 489193 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"metadata":{"_cell_guid":"cae0096e-5a09-2304-184e-e4afebe753b8"},"cell_type":"markdown","source":"Wow! Our resulting table contains counts for 31,675 different words!"},{"metadata":{"_cell_guid":"781fb862-f8c2-1e5e-af6f-16f6922eb6c8"},"cell_type":"markdown","source":"Now, let's train a logistic regression model using this data.  \nIn the cell below, we're simply naming our model, then [fitting](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit) the model based on our X and Y values."},{"metadata":{"_cell_guid":"5f4d9232-5b01-4c65-a933-eda036a25216","trusted":true},"cell_type":"code","source":"basicmodel = LogisticRegression()\nbasicmodel = basicmodel.fit(basictrain, train[\"Label\"])","execution_count":18,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n","name":"stderr"}]},{"metadata":{"_cell_guid":"5e43218f-9c22-bb3c-8e3f-964857c1c7bb"},"cell_type":"markdown","source":"Our model is ready to go, so let's set up our test data.  \nHere, we're just going to repeat the steps we used to prep our training data, then [predict](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict) whether the DJIA increased or decreased for each day in the test dataset."},{"metadata":{"_cell_guid":"2c51dcd0-0d7a-41d5-6445-0eadf1d18e87","trusted":true},"cell_type":"code","source":"testheadlines = []\nfor row in range(0,len(test.index)):\n    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\nbasictest = basicvectorizer.transform(testheadlines)\npredictions = basicmodel.predict(basictest)","execution_count":23,"outputs":[]},{"metadata":{"_cell_guid":"42e8b6a7-b138-ac21-a64b-3ddb3717aa19"},"cell_type":"markdown","source":"The predictions are set, so let's use a [crosstab](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.crosstab.html) to take a look at the results!"},{"metadata":{"_cell_guid":"acd37c68-a42c-0f95-cd05-cc9e2aae6a41"},"cell_type":"markdown","source":"Prediction accuracy is just over 42%. It seems like this model isn't too reliable.  \nNow, let's also take a look at the coefficients of our model. (Excellent request from [Lucie](https://www.kaggle.com/luciegattepaille)!)"},{"metadata":{"_cell_guid":"2db3b5d0-f86a-5d23-3ae5-7fe725dbd4ab","trusted":true},"cell_type":"code","source":"pd.crosstab(test[\"Label\"], predictions, rownames=[\"Actual\"], colnames=[\"Predicted\"])","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"Predicted   0    1\nActual            \n0          61  125\n1          92  100","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Predicted</th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n    <tr>\n      <th>Actual</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>61</td>\n      <td>125</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>92</td>\n      <td>100</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"3345bcdf-e9e5-a1da-18e7-21ba26824a10"},"cell_type":"markdown","source":"The cell below will get a list of the names from our CountVectorizer and a list of the coefficients from our model, then combine the two lists into a Pandas dataframe.  \nOnce that's made, we can sort it and check out the top 10 positive and negative coefficients."},{"metadata":{"_cell_guid":"9d2c7daa-8e28-9849-1fc6-4b0fab9967cf","trusted":true},"cell_type":"code","source":"basicwords = basicvectorizer.get_feature_names()\nbasiccoeffs = basicmodel.coef_.tolist()[0]\ncoeffdf = pd.DataFrame({'Word' : basicwords, \n                        'Coefficient' : basiccoeffs})\ncoeffdf = coeffdf.sort_values(['Coefficient', 'Word'], ascending=[0, 1])\ncoeffdf.head(10)","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"            Word  Coefficient\n19419    nigeria     0.497872\n25261       self     0.452523\n29286         tv     0.427959\n15998      korea     0.425862\n20135   olympics     0.425712\n15843      kills     0.411638\n26323         so     0.411301\n29256       turn     0.394834\n10874      fears     0.388540\n28274  territory     0.384034","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Coefficient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19419</th>\n      <td>nigeria</td>\n      <td>0.497872</td>\n    </tr>\n    <tr>\n      <th>25261</th>\n      <td>self</td>\n      <td>0.452523</td>\n    </tr>\n    <tr>\n      <th>29286</th>\n      <td>tv</td>\n      <td>0.427959</td>\n    </tr>\n    <tr>\n      <th>15998</th>\n      <td>korea</td>\n      <td>0.425862</td>\n    </tr>\n    <tr>\n      <th>20135</th>\n      <td>olympics</td>\n      <td>0.425712</td>\n    </tr>\n    <tr>\n      <th>15843</th>\n      <td>kills</td>\n      <td>0.411638</td>\n    </tr>\n    <tr>\n      <th>26323</th>\n      <td>so</td>\n      <td>0.411301</td>\n    </tr>\n    <tr>\n      <th>29256</th>\n      <td>turn</td>\n      <td>0.394834</td>\n    </tr>\n    <tr>\n      <th>10874</th>\n      <td>fears</td>\n      <td>0.388540</td>\n    </tr>\n    <tr>\n      <th>28274</th>\n      <td>territory</td>\n      <td>0.384034</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"5ea266d6-6a99-10ee-a109-7e82406225df","trusted":true},"cell_type":"code","source":"coeffdf.tail(10)","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"            Word  Coefficient\n27299   students    -0.424441\n8478         did    -0.427078\n6683       congo    -0.431908\n12818    hacking    -0.444041\n7139     country    -0.448565\n16949        low    -0.463092\n3651       begin    -0.470475\n25433        sex    -0.494526\n24754  sanctions    -0.549718\n24542        run    -0.587751","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Coefficient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>27299</th>\n      <td>students</td>\n      <td>-0.424441</td>\n    </tr>\n    <tr>\n      <th>8478</th>\n      <td>did</td>\n      <td>-0.427078</td>\n    </tr>\n    <tr>\n      <th>6683</th>\n      <td>congo</td>\n      <td>-0.431908</td>\n    </tr>\n    <tr>\n      <th>12818</th>\n      <td>hacking</td>\n      <td>-0.444041</td>\n    </tr>\n    <tr>\n      <th>7139</th>\n      <td>country</td>\n      <td>-0.448565</td>\n    </tr>\n    <tr>\n      <th>16949</th>\n      <td>low</td>\n      <td>-0.463092</td>\n    </tr>\n    <tr>\n      <th>3651</th>\n      <td>begin</td>\n      <td>-0.470475</td>\n    </tr>\n    <tr>\n      <th>25433</th>\n      <td>sex</td>\n      <td>-0.494526</td>\n    </tr>\n    <tr>\n      <th>24754</th>\n      <td>sanctions</td>\n      <td>-0.549718</td>\n    </tr>\n    <tr>\n      <th>24542</th>\n      <td>run</td>\n      <td>-0.587751</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"0a1d664f-9f87-f30d-3c90-83c2a774257b"},"cell_type":"markdown","source":"Our most positive words don't seem particularly interesting, however there are some negative sounding words within our bottom 10, such as \"sanctions,\" \"low,\" and \"hacking.\"  \nMaybe the saying \"no news is good news\" is true here?"},{"metadata":{"_cell_guid":"aabb5e54-c8b5-e952-0701-8fe3febd64b3"},"cell_type":"markdown","source":"----------"},{"metadata":{"_cell_guid":"d4d97261-5f0c-bbd6-f3bd-87cd6f39f224"},"cell_type":"markdown","source":"# Advanced Modeling"},{"metadata":{"_cell_guid":"8d86b6ae-68f1-90d7-22c3-6ab1a9dfe9e9"},"cell_type":"markdown","source":"The technique we just used is known as a **bag-of-words** model. We essentially placed all of our headlines into a \"bag\" and counted the words as we pulled them out.  \nHowever, most people would agree that a single word doesn't always have enough meaning by itself.  \nObviously, we need to consider the rest of the words in the sentence as well!  "},{"metadata":{"_cell_guid":"fd5f8e9e-7936-0a71-78cf-89d8c1ab61ae"},"cell_type":"markdown","source":"This is where the **n-gram** model comes in.  \nIn this model, n represents the length of a sequence of words to be counted.  \nThis means our bag-of-words model was the same as an n-gram model where n = 1.  \nSo now, let's see what happens when we run an n-gram model where n = 2."},{"metadata":{"_cell_guid":"aa207db9-951a-29da-2fe9-021502e24780"},"cell_type":"markdown","source":"Below, we'll create a new CountVectorizer with the n-gram parameter set to 2 instead of the default value of 1."},{"metadata":{"_cell_guid":"1bfe7bd0-6330-23e1-da05-41a072249291","trusted":true},"cell_type":"code","source":"advancedvectorizer = CountVectorizer(ngram_range=(2,2))\nadvancedtrain = advancedvectorizer.fit_transform(trainheadlines)","execution_count":27,"outputs":[]},{"metadata":{"_cell_guid":"a84ee6fa-d38b-ba5d-ed08-cd32ae7b479b"},"cell_type":"markdown","source":"Now that we've run our vectorizer, let's see what our data looks like this time around."},{"metadata":{"_cell_guid":"be873375-6cba-796c-69a1-5218118af3df","trusted":true},"cell_type":"code","source":"print(advancedtrain.shape)","execution_count":28,"outputs":[{"output_type":"stream","text":"(1611, 366721)\n","name":"stdout"}]},{"metadata":{"_cell_guid":"c0f41320-bb02-d8d5-7a03-9e64e66c978b"},"cell_type":"markdown","source":"This time we have 366,721 unique variables representing two-word combinations!  \nAnd here I thought last time was big..."},{"metadata":{"_cell_guid":"20031a48-cbe5-4b60-116c-6a90e9017ac8"},"cell_type":"markdown","source":"So, just like last time, let's name and fit our regression model."},{"metadata":{"_cell_guid":"82609b09-1c0d-92e5-739a-dad9859ea2ed","trusted":true},"cell_type":"code","source":"advancedmodel = LogisticRegression()\nadvancedmodel = advancedmodel.fit(advancedtrain, train[\"Label\"])","execution_count":29,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n","name":"stderr"}]},{"metadata":{"_cell_guid":"685a6540-2e70-0aa3-d6a2-50df0750d1c9"},"cell_type":"markdown","source":"And again like last time, let's transform our test data and make some predictions!"},{"metadata":{"_cell_guid":"7e30825f-fd0b-f112-34d2-759ddab1de6b","trusted":true},"cell_type":"code","source":"testheadlines = []\nfor row in range(0,len(test.index)):\n    testheadlines.append(' '.join(str(x) for x in test.iloc[row,2:27]))\nadvancedtest = advancedvectorizer.transform(testheadlines)\nadvpredictions = advancedmodel.predict(advancedtest)","execution_count":30,"outputs":[]},{"metadata":{"_cell_guid":"452d263e-e523-596a-927d-8fefcec268c7"},"cell_type":"markdown","source":"Crosstab says...!"},{"metadata":{"_cell_guid":"16c834ce-8bbc-cb82-58c4-5d11cbf64c64","trusted":true},"cell_type":"code","source":"pd.crosstab(test[\"Label\"], advpredictions, rownames=[\"Actual\"], colnames=[\"Predicted\"])","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"Predicted   0    1\nActual            \n0          66  120\n1          45  147","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th>Predicted</th>\n      <th>0</th>\n      <th>1</th>\n    </tr>\n    <tr>\n      <th>Actual</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>66</td>\n      <td>120</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45</td>\n      <td>147</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"67f0954f-9117-2852-9316-e6c3c4de5715"},"cell_type":"markdown","source":"This time we're up to nearly 57% prediction accuracy.  \nWe might only consider this a slight improvement, but keep in mind that we've barely scratched the surface of NLP here, and we haven't even touched more advanced machine learning techniques.  \nLet's check out our coefficients again as well!"},{"metadata":{"_cell_guid":"5baeabb3-03b4-5856-c9c3-a8f5b90acaf6","trusted":true},"cell_type":"code","source":"advwords = advancedvectorizer.get_feature_names()\nadvcoeffs = advancedmodel.coef_.tolist()[0]\nadvcoeffdf = pd.DataFrame({'Words' : advwords, \n                        'Coefficient' : advcoeffs})\nadvcoeffdf = advcoeffdf.sort_values(['Coefficient', 'Words'], ascending=[0, 1])\nadvcoeffdf.head(10)","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"            Words  Coefficient\n272047   right to     0.286533\n24710   and other     0.275274\n285392     set to     0.274698\n316194  the first     0.262873\n157511   in china     0.227943\n159522   in south     0.224184\n125870   found in     0.219130\n124411  forced to     0.216726\n173246     it has     0.211137\n322590    this is     0.209239","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Coefficient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>272047</th>\n      <td>right to</td>\n      <td>0.286533</td>\n    </tr>\n    <tr>\n      <th>24710</th>\n      <td>and other</td>\n      <td>0.275274</td>\n    </tr>\n    <tr>\n      <th>285392</th>\n      <td>set to</td>\n      <td>0.274698</td>\n    </tr>\n    <tr>\n      <th>316194</th>\n      <td>the first</td>\n      <td>0.262873</td>\n    </tr>\n    <tr>\n      <th>157511</th>\n      <td>in china</td>\n      <td>0.227943</td>\n    </tr>\n    <tr>\n      <th>159522</th>\n      <td>in south</td>\n      <td>0.224184</td>\n    </tr>\n    <tr>\n      <th>125870</th>\n      <td>found in</td>\n      <td>0.219130</td>\n    </tr>\n    <tr>\n      <th>124411</th>\n      <td>forced to</td>\n      <td>0.216726</td>\n    </tr>\n    <tr>\n      <th>173246</th>\n      <td>it has</td>\n      <td>0.211137</td>\n    </tr>\n    <tr>\n      <th>322590</th>\n      <td>this is</td>\n      <td>0.209239</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"b80cc33e-8016-3409-e6ff-8fdcb5481db4","trusted":true},"cell_type":"code","source":"advcoeffdf.tail(10)","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"              Words  Coefficient\n326846      to help    -0.198495\n118707      fire on    -0.201654\n155038        if he    -0.209702\n242528   people are    -0.211303\n31669    around the    -0.213362\n321333     there is    -0.215699\n327113      to kill    -0.221812\n340714        up in    -0.226289\n358917    with iran    -0.227516\n315485  the country    -0.331153","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Words</th>\n      <th>Coefficient</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>326846</th>\n      <td>to help</td>\n      <td>-0.198495</td>\n    </tr>\n    <tr>\n      <th>118707</th>\n      <td>fire on</td>\n      <td>-0.201654</td>\n    </tr>\n    <tr>\n      <th>155038</th>\n      <td>if he</td>\n      <td>-0.209702</td>\n    </tr>\n    <tr>\n      <th>242528</th>\n      <td>people are</td>\n      <td>-0.211303</td>\n    </tr>\n    <tr>\n      <th>31669</th>\n      <td>around the</td>\n      <td>-0.213362</td>\n    </tr>\n    <tr>\n      <th>321333</th>\n      <td>there is</td>\n      <td>-0.215699</td>\n    </tr>\n    <tr>\n      <th>327113</th>\n      <td>to kill</td>\n      <td>-0.221812</td>\n    </tr>\n    <tr>\n      <th>340714</th>\n      <td>up in</td>\n      <td>-0.226289</td>\n    </tr>\n    <tr>\n      <th>358917</th>\n      <td>with iran</td>\n      <td>-0.227516</td>\n    </tr>\n    <tr>\n      <th>315485</th>\n      <td>the country</td>\n      <td>-0.331153</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_cell_guid":"98b308d6-d359-97b4-401b-5ee2a8825219"},"cell_type":"markdown","source":"It seems that the results this time were fairly similar. Most of the positive bigrams are unremarkable, while a few of the negative ones like \"bin laden\" and \"threatens to\" could be considered to carry some negative meaning."},{"metadata":{"_cell_guid":"1e2d5df8-c48f-6edf-785d-85a9f8d92a26"},"cell_type":"markdown","source":"----------"},{"metadata":{"_cell_guid":"91b9197d-ee3a-6b3c-0858-a63ac09c7f50"},"cell_type":"markdown","source":"# What's next?"},{"metadata":{"_cell_guid":"a2ae4a28-1023-2586-c445-8c5e8fd6ecc6"},"cell_type":"markdown","source":"If you'd like to keep going forward with this notebook, here are a couple of project ideas:  \n- Experiment with different n values using the n-gram model  \n- Use previous days' headlines to truly \"predict\" whether the DJIA will rise or fall  \n- Try a machine learning algorithm instead of the basic logistic regression used in this notebook"},{"metadata":{"_cell_guid":"a0ca7639-57ae-cbed-c514-01c07667650e"},"cell_type":"markdown","source":"Thanks again for reading! I hope you found this helpful!"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":1}